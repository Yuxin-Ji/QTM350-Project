{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws rekognition help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[beryl1](https://350-rekog-project.s3.amazonaws.com/beryl1.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[together1](https://350-rekog-project.s3.amazonaws.com/together1.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=client.compare_faces(SimilarityThreshold=80,\n",
    "                                  SourceImage={'S3Object':{'Bucket':\"350-rekog-project\",'Name':\"beryl1.jpeg\"}},\n",
    "                                  TargetImage={'S3Object':{'Bucket':\"350-rekog-project\",'Name':\"together1.jpeg\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The face at 0.5722591280937195 0.41717708110809326 matches with 99.89863586425781% confidence\n",
      "The face at 0.3406957685947418 0.4428347945213318 matches with 99.37723541259766% confidence\n",
      "The face at 0.1799880415201187 0.4139992594718933 dose not match with 99.99813079833984% confidence\n"
     ]
    }
   ],
   "source": [
    "for faceMatch in response['FaceMatches']:\n",
    "        position = faceMatch['Face']['BoundingBox']\n",
    "        similarity = str(faceMatch['Similarity'])\n",
    "        print('The face at ' +\n",
    "               str(position['Left']) + ' ' +\n",
    "               str(position['Top']) +\n",
    "               ' matches with ' + similarity + '% confidence')\n",
    "for faceNotMatch in response['UnmatchedFaces']:\n",
    "    position = faceNotMatch['BoundingBox']\n",
    "    confidence = str(faceNotMatch['Confidence'])\n",
    "    print('The face at ' +\n",
    "            str(position['Left']) + ' ' +\n",
    "            str(position['Top']) +\n",
    "            ' dose not match with ' + confidence + '% confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SourceImageFace': {'BoundingBox': {'Width': 0.4034557342529297,\n",
       "   'Height': 0.46883130073547363,\n",
       "   'Left': 0.2250816971063614,\n",
       "   'Top': 0.14957624673843384},\n",
       "  'Confidence': 99.99610137939453},\n",
       " 'FaceMatches': [{'Similarity': 99.89863586425781,\n",
       "   'Face': {'BoundingBox': {'Width': 0.13176371157169342,\n",
       "     'Height': 0.1304168701171875,\n",
       "     'Left': 0.5722591280937195,\n",
       "     'Top': 0.41717708110809326},\n",
       "    'Confidence': 99.99797058105469,\n",
       "    'Landmarks': [{'Type': 'eyeLeft',\n",
       "      'X': 0.5984861254692078,\n",
       "      'Y': 0.47112470865249634},\n",
       "     {'Type': 'eyeRight', 'X': 0.658948540687561, 'Y': 0.4712055027484894},\n",
       "     {'Type': 'mouthLeft', 'X': 0.6055641174316406, 'Y': 0.5137875080108643},\n",
       "     {'Type': 'mouthRight', 'X': 0.6560426354408264, 'Y': 0.5139992237091064},\n",
       "     {'Type': 'nose', 'X': 0.6206967234611511, 'Y': 0.49473461508750916}],\n",
       "    'Pose': {'Roll': -1.168199062347412,\n",
       "     'Yaw': -9.636792182922363,\n",
       "     'Pitch': 1.719215750694275},\n",
       "    'Quality': {'Brightness': 57.9803466796875,\n",
       "     'Sharpness': 32.20803451538086}}},\n",
       "  {'Similarity': 99.37723541259766,\n",
       "   'Face': {'BoundingBox': {'Width': 0.13136985898017883,\n",
       "     'Height': 0.12316276133060455,\n",
       "     'Left': 0.3406957685947418,\n",
       "     'Top': 0.4428347945213318},\n",
       "    'Confidence': 99.99877166748047,\n",
       "    'Landmarks': [{'Type': 'eyeLeft',\n",
       "      'X': 0.374421626329422,\n",
       "      'Y': 0.48981422185897827},\n",
       "     {'Type': 'eyeRight', 'X': 0.4338950514793396, 'Y': 0.49254482984542847},\n",
       "     {'Type': 'mouthLeft', 'X': 0.3775508999824524, 'Y': 0.5319766998291016},\n",
       "     {'Type': 'mouthRight', 'X': 0.4273218512535095, 'Y': 0.5343700647354126},\n",
       "     {'Type': 'nose', 'X': 0.3980119526386261, 'Y': 0.5151817798614502}],\n",
       "    'Pose': {'Roll': 2.946230411529541,\n",
       "     'Yaw': -5.720349311828613,\n",
       "     'Pitch': 0.2659147381782532},\n",
       "    'Quality': {'Brightness': 65.06717681884766,\n",
       "     'Sharpness': 38.89601135253906}}}],\n",
       " 'UnmatchedFaces': [{'BoundingBox': {'Width': 0.10746818780899048,\n",
       "    'Height': 0.13813892006874084,\n",
       "    'Left': 0.1799880415201187,\n",
       "    'Top': 0.4139992594718933},\n",
       "   'Confidence': 99.99813079833984,\n",
       "   'Landmarks': [{'Type': 'eyeLeft',\n",
       "     'X': 0.20783153176307678,\n",
       "     'Y': 0.4655102491378784},\n",
       "    {'Type': 'eyeRight', 'X': 0.2660055160522461, 'Y': 0.4707227051258087},\n",
       "    {'Type': 'mouthLeft', 'X': 0.20262490212917328, 'Y': 0.5149248242378235},\n",
       "    {'Type': 'mouthRight', 'X': 0.2510899007320404, 'Y': 0.5191515684127808},\n",
       "    {'Type': 'nose', 'X': 0.2373422384262085, 'Y': 0.4962517321109772}],\n",
       "   'Pose': {'Roll': 8.612255096435547,\n",
       "    'Yaw': 12.113481521606445,\n",
       "    'Pitch': -0.10833657532930374},\n",
       "   'Quality': {'Brightness': 87.4827651977539,\n",
       "    'Sharpness': 53.330047607421875}}],\n",
       " 'ResponseMetadata': {'RequestId': '1c32d145-f086-4a93-a74a-f5b6083b53a6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Wed, 18 Nov 2020 00:59:25 GMT',\n",
       "   'x-amzn-requestid': '1c32d145-f086-4a93-a74a-f5b6083b53a6',\n",
       "   'content-length': '2270',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing about twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "fs = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to extract similarity with beryl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_similarity(photo):\n",
    "    try:\n",
    "        similarity = []\n",
    "        comparison = client.compare_faces(\n",
    "            SourceImage= {'S3Object':{'Bucket':\"350-rekog-project\", 'Name':'beryl1.jpeg'}},\n",
    "            TargetImage = {'S3Object':{'Bucket':\"350-rekog-project\",'Name':photo}})\n",
    "        result = {}\n",
    "        i = 0\n",
    "        for faceMatch in comparison['FaceMatches']:\n",
    "            position = faceMatch['Face']['BoundingBox']\n",
    "            similarity = faceMatch['Similarity']\n",
    "            result[i] = {}\n",
    "            result[i]['similarity'] = similarity\n",
    "            result[i]['position'] = position['Left']\n",
    "            i+=1\n",
    "        \n",
    "    except Exception:\n",
    "        similarity = np.nan\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'similarity': 99.89863586425781, 'position': 0.5722591280937195},\n",
       " 1: {'similarity': 99.37723541259766, 'position': 0.3406957685947418}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together1 = \"together1.jpeg\"\n",
    "extract_similarity(together1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of the photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amber1.jpg',\n",
       " 'amber2.jpg',\n",
       " 'amber3.jpg',\n",
       " 'beryl1.jpeg',\n",
       " 'beryl2.jpg',\n",
       " 'beryl3.jpeg',\n",
       " 'together1.jpeg',\n",
       " 'together2.jpg',\n",
       " 'together3.jpeg',\n",
       " 'together4.jpg',\n",
       " 'together5.jpeg',\n",
       " 'together6.jpg']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_resource = boto3.resource('s3')\n",
    "my_bucket = s3_resource.Bucket('350-rekog-project')\n",
    "summaries = my_bucket.objects.all()\n",
    "image_names = [image.key for image  in summaries][-12:]\n",
    "image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['together1.jpeg',\n",
       " 'together2.jpg',\n",
       " 'together3.jpeg',\n",
       " 'together4.jpg',\n",
       " 'together5.jpeg',\n",
       " 'together6.jpg']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together = image_names[-6:]\n",
    "together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "togetherDF = pd.DataFrame({'Name': together})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "higherSimilarity = []\n",
    "lowerSimilarity = []\n",
    "higherPosition = []\n",
    "lowerPosition = []\n",
    "for photo in together:\n",
    "    result = extract_similarity(photo)\n",
    "    higherSimilarity.append(result[0]['similarity'])\n",
    "    lowerSimilarity.append(result[1]['similarity'])\n",
    "    higherPosition.append(result[0]['position'])\n",
    "    lowerPosition.append(result[1]['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "togetherDF['higherSimilarity'] = higherSimilarity\n",
    "togetherDF['lowerSimilarity'] = lowerSimilarity\n",
    "togetherDF['higherPosition'] = higherPosition\n",
    "togetherDF['lowerPosition'] = lowerPosition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>higherSimilarity</th>\n",
       "      <th>lowerSimilarity</th>\n",
       "      <th>higherPosition</th>\n",
       "      <th>lowerPosition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>together1.jpeg</td>\n",
       "      <td>99.898636</td>\n",
       "      <td>99.377235</td>\n",
       "      <td>0.572259</td>\n",
       "      <td>0.340696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>together2.jpg</td>\n",
       "      <td>99.754501</td>\n",
       "      <td>98.325134</td>\n",
       "      <td>0.045990</td>\n",
       "      <td>0.241981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>together3.jpeg</td>\n",
       "      <td>99.580872</td>\n",
       "      <td>97.708191</td>\n",
       "      <td>0.393376</td>\n",
       "      <td>0.521831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>together4.jpg</td>\n",
       "      <td>99.805557</td>\n",
       "      <td>99.684677</td>\n",
       "      <td>0.243969</td>\n",
       "      <td>0.648528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>together5.jpeg</td>\n",
       "      <td>99.821136</td>\n",
       "      <td>99.256424</td>\n",
       "      <td>0.140115</td>\n",
       "      <td>0.651509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>together6.jpg</td>\n",
       "      <td>99.693970</td>\n",
       "      <td>95.881134</td>\n",
       "      <td>0.580760</td>\n",
       "      <td>0.276223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name  higherSimilarity  lowerSimilarity  higherPosition  \\\n",
       "0  together1.jpeg         99.898636        99.377235        0.572259   \n",
       "1   together2.jpg         99.754501        98.325134        0.045990   \n",
       "2  together3.jpeg         99.580872        97.708191        0.393376   \n",
       "3   together4.jpg         99.805557        99.684677        0.243969   \n",
       "4  together5.jpeg         99.821136        99.256424        0.140115   \n",
       "5   together6.jpg         99.693970        95.881134        0.580760   \n",
       "\n",
       "   lowerPosition  \n",
       "0       0.340696  \n",
       "1       0.241981  \n",
       "2       0.521831  \n",
       "3       0.648528  \n",
       "4       0.651509  \n",
       "5       0.276223  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "togetherDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will look at the photo and identify the twins by ourself.\n",
    "0 means beryl is on the left, 1 means beryl is on the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "berylPos = [1,0,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctness = []\n",
    "for i in range(togetherDF.shape[0]):\n",
    "    if togetherDF.loc[i]['higherPosition'] < togetherDF.loc[i]['lowerPosition'] and berylPos[i] == 0:\n",
    "                         correctness.append(0)\n",
    "    elif togetherDF.loc[i]['higherPosition'] > togetherDF.loc[i]['lowerPosition'] and berylPos[i] == 1:\n",
    "                           correctness.append(0)\n",
    "    else:\n",
    "                           correctness.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "togetherDF['correctness'] = correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>higherSimilarity</th>\n",
       "      <th>lowerSimilarity</th>\n",
       "      <th>higherPosition</th>\n",
       "      <th>lowerPosition</th>\n",
       "      <th>correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>together1.jpeg</td>\n",
       "      <td>99.898636</td>\n",
       "      <td>99.377235</td>\n",
       "      <td>0.572259</td>\n",
       "      <td>0.340696</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>together2.jpg</td>\n",
       "      <td>99.754501</td>\n",
       "      <td>98.325134</td>\n",
       "      <td>0.045990</td>\n",
       "      <td>0.241981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>together3.jpeg</td>\n",
       "      <td>99.580872</td>\n",
       "      <td>97.708191</td>\n",
       "      <td>0.393376</td>\n",
       "      <td>0.521831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>together4.jpg</td>\n",
       "      <td>99.805557</td>\n",
       "      <td>99.684677</td>\n",
       "      <td>0.243969</td>\n",
       "      <td>0.648528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>together5.jpeg</td>\n",
       "      <td>99.821136</td>\n",
       "      <td>99.256424</td>\n",
       "      <td>0.140115</td>\n",
       "      <td>0.651509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>together6.jpg</td>\n",
       "      <td>99.693970</td>\n",
       "      <td>95.881134</td>\n",
       "      <td>0.580760</td>\n",
       "      <td>0.276223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name  higherSimilarity  lowerSimilarity  higherPosition  \\\n",
       "0  together1.jpeg         99.898636        99.377235        0.572259   \n",
       "1   together2.jpg         99.754501        98.325134        0.045990   \n",
       "2  together3.jpeg         99.580872        97.708191        0.393376   \n",
       "3   together4.jpg         99.805557        99.684677        0.243969   \n",
       "4  together5.jpeg         99.821136        99.256424        0.140115   \n",
       "5   together6.jpg         99.693970        95.881134        0.580760   \n",
       "\n",
       "   lowerPosition  correctness  \n",
       "0       0.340696            0  \n",
       "1       0.241981            0  \n",
       "2       0.521831            0  \n",
       "3       0.648528            0  \n",
       "4       0.651509            0  \n",
       "5       0.276223            0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "togetherDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(togetherDF['correctness'])==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that though AWS rocognize both Amber and Beryl as Beryl, but it successfully assign higher similarity scores for beryl. We will next see the distribution of their similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot = togetherDF.boxplot(column = ['higherSimilarity', 'lowerSimilarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the boxplot, we can see that AWS identifies beryl with similarity scores higher than 99.5 overall and the range is tiny, while the similarity scores between beryl and amber is overall lower and the range is wider. In other words, AWS actually performs very well on identifying twins as it gives overall higher similarity scores for the correct person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also tune the parameter of the function compare_faces by setting the SimilarityThreshold very high (i.e. 99.5), then we may be able to identify only one person in the photo as beryl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The face at 0.5722591280937195 0.41717708110809326 matches with 99.89863586425781% confidence\n",
      "The face at 0.3406957685947418 0.4428347945213318 dose not match with 99.99877166748047% confidence\n",
      "The face at 0.1799880415201187 0.4139992594718933 dose not match with 99.99813079833984% confidence\n"
     ]
    }
   ],
   "source": [
    "response=client.compare_faces(SimilarityThreshold=99.5,\n",
    "                                  SourceImage={'S3Object':{'Bucket':\"350-rekog-project\",'Name':\"beryl1.jpeg\"}},\n",
    "                                  TargetImage={'S3Object':{'Bucket':\"350-rekog-project\",'Name':\"together1.jpeg\"}})\n",
    "for faceMatch in response['FaceMatches']:\n",
    "        position = faceMatch['Face']['BoundingBox']\n",
    "        similarity = str(faceMatch['Similarity'])\n",
    "        print('The face at ' +\n",
    "               str(position['Left']) + ' ' +\n",
    "               str(position['Top']) +\n",
    "               ' matches with ' + similarity + '% confidence')\n",
    "for faceNotMatch in response['UnmatchedFaces']:\n",
    "    position = faceNotMatch['BoundingBox']\n",
    "    confidence = str(faceNotMatch['Confidence'])\n",
    "    print('The face at ' +\n",
    "            str(position['Left']) + ' ' +\n",
    "            str(position['Top']) +\n",
    "            ' dose not match with ' + confidence + '% confidence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we will miss 'true beryl' in some other cases because as we can see from the boxplots, the range of the similarity scores overlaps at some points. Thus we cannot find a 'best' similarity threshold that can distinguish amber from beryl without missing true beryl. Except from the ability to distinguish between twins, in the time of a pendamic, we would also like to discover whether masks will impact the recognition. And we would extend the data to people and their photos with glasses, masks and funny faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warmup and Setup on minor facial variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Labels': [{'Name': 'Finger',\n",
       "   'Confidence': 95.55704498291016,\n",
       "   'Instances': [],\n",
       "   'Parents': []},\n",
       "  {'Name': 'Person',\n",
       "   'Confidence': 91.80702209472656,\n",
       "   'Instances': [{'BoundingBox': {'Width': 0.9945007562637329,\n",
       "      'Height': 0.950671374797821,\n",
       "      'Left': 0.0,\n",
       "      'Top': 0.03495144471526146},\n",
       "     'Confidence': 91.80702209472656}],\n",
       "   'Parents': []},\n",
       "  {'Name': 'Human',\n",
       "   'Confidence': 91.80702209472656,\n",
       "   'Instances': [],\n",
       "   'Parents': []},\n",
       "  {'Name': 'Apparel',\n",
       "   'Confidence': 91.67005920410156,\n",
       "   'Instances': [],\n",
       "   'Parents': []},\n",
       "  {'Name': 'Clothing',\n",
       "   'Confidence': 91.67005920410156,\n",
       "   'Instances': [],\n",
       "   'Parents': []},\n",
       "  {'Name': 'Face',\n",
       "   'Confidence': 74.54094696044922,\n",
       "   'Instances': [],\n",
       "   'Parents': [{'Name': 'Person'}]},\n",
       "  {'Name': 'Skin',\n",
       "   'Confidence': 67.7409439086914,\n",
       "   'Instances': [],\n",
       "   'Parents': []},\n",
       "  {'Name': 'Lip',\n",
       "   'Confidence': 67.057373046875,\n",
       "   'Instances': [],\n",
       "   'Parents': []},\n",
       "  {'Name': 'Mouth',\n",
       "   'Confidence': 67.057373046875,\n",
       "   'Instances': [],\n",
       "   'Parents': []},\n",
       "  {'Name': 'Hat',\n",
       "   'Confidence': 56.50393295288086,\n",
       "   'Instances': [],\n",
       "   'Parents': [{'Name': 'Clothing'}]},\n",
       "  {'Name': 'Home Decor',\n",
       "   'Confidence': 56.3720817565918,\n",
       "   'Instances': [],\n",
       "   'Parents': []}],\n",
       " 'LabelModelVersion': '2.0',\n",
       " 'ResponseMetadata': {'RequestId': '55dd419a-c8ab-4e6e-9bb6-242b3163a51b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Wed, 18 Nov 2020 00:59:39 GMT',\n",
       "   'x-amzn-requestid': '55dd419a-c8ab-4e6e-9bb6-242b3163a51b',\n",
       "   'content-length': '1049',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.detect_labels(Image = {'S3Object':{'Bucket':'350project-image', 'Name':'a1.jpg'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare faces when 1) original 2) glass-wearing 3) mask-covering 4) making funny faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.compare_faces(SimilarityThreshold=80,\n",
    "                                  SourceImage={'S3Object':{'Bucket':\"350project-image\",'Name':\"a1.jpg\"}},\n",
    "                                  TargetImage={'S3Object':{'Bucket':\"350project-image\",'Name':\"a2.jpg\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The face at 0.26413869857788086 0.20291969180107117 matches with 99.99996185302734% confidence\n"
     ]
    }
   ],
   "source": [
    "for faceMatch in response['FaceMatches']:\n",
    "        position = faceMatch['Face']['BoundingBox']\n",
    "        similarity = str(faceMatch['Similarity'])\n",
    "        print('The face at ' +\n",
    "               str(position['Left']) + ' ' +\n",
    "               str(position['Top']) +\n",
    "               ' matches with ' + similarity + '% confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for faceNotMatch in response['UnmatchedFaces']:\n",
    "    position = faceNotMatch['BoundingBox']\n",
    "    confidence = str(faceNotMatch['Confidence'])\n",
    "    print('The face at ' +\n",
    "            str(position['Left']) + ' ' +\n",
    "            str(position['Top']) +\n",
    "            ' dose not match with ' + confidence + '% confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SourceImageFace': {'BoundingBox': {'Width': 0.5884437561035156,\n",
       "   'Height': 0.633808970451355,\n",
       "   'Left': 0.23545102775096893,\n",
       "   'Top': 0.1488596349954605},\n",
       "  'Confidence': 99.99200439453125},\n",
       " 'FaceMatches': [{'Similarity': 99.99996185302734,\n",
       "   'Face': {'BoundingBox': {'Width': 0.5546112060546875,\n",
       "     'Height': 0.5667304992675781,\n",
       "     'Left': 0.26413869857788086,\n",
       "     'Top': 0.20291969180107117},\n",
       "    'Confidence': 99.98955535888672,\n",
       "    'Landmarks': [{'Type': 'eyeLeft',\n",
       "      'X': 0.42226552963256836,\n",
       "      'Y': 0.4526117146015167},\n",
       "     {'Type': 'eyeRight', 'X': 0.6778354048728943, 'Y': 0.4499421715736389},\n",
       "     {'Type': 'mouthLeft', 'X': 0.4446648061275482, 'Y': 0.6642223000526428},\n",
       "     {'Type': 'mouthRight', 'X': 0.6580995321273804, 'Y': 0.661880373954773},\n",
       "     {'Type': 'nose', 'X': 0.5528274774551392, 'Y': 0.5827391743659973}],\n",
       "    'Pose': {'Roll': -1.1150751113891602,\n",
       "     'Yaw': 1.0638971328735352,\n",
       "     'Pitch': -5.5680832862854},\n",
       "    'Quality': {'Brightness': 91.87378692626953,\n",
       "     'Sharpness': 95.51618957519531}}}],\n",
       " 'UnmatchedFaces': [],\n",
       " 'ResponseMetadata': {'RequestId': '84d97784-7a3c-4d17-ab2e-e35142d9be92',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Wed, 18 Nov 2020 00:59:40 GMT',\n",
       "   'x-amzn-requestid': '84d97784-7a3c-4d17-ab2e-e35142d9be92',\n",
       "   'content-length': '908',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "fs = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Case for picture a group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_similarity(photo):\n",
    "    try:\n",
    "        similarity = []\n",
    "        comparison = client.compare_faces(\n",
    "            SourceImage= {'S3Object':{'Bucket':\"350project-image\", 'Name':'a1.jpg'}},\n",
    "            TargetImage = {'S3Object':{'Bucket':\"350project-image\",'Name':photo}})\n",
    "        result = {}\n",
    "        i = 0\n",
    "        for faceMatch in comparison['FaceMatches']:\n",
    "            position = faceMatch['Face']['BoundingBox']\n",
    "            similarity = faceMatch['Similarity']\n",
    "            result[i] = {}\n",
    "            result[i]['similarity'] = similarity\n",
    "            result[i]['position'] = position['Left']\n",
    "            i+=1\n",
    "        \n",
    "    except Exception:\n",
    "        similarity = np.nan\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'similarity': 99.99996185302734, 'position': 0.26413869857788086}}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl1 = \"a2.jpg\"\n",
    "extract_similarity(cl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a list of photoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_similarity(photo,source_photo):\n",
    "    try:\n",
    "        similarity = []\n",
    "        comparison = client.compare_faces(\n",
    "            SourceImage= {'S3Object':{'Bucket':\"350project-image\", 'Name':source_photo}},\n",
    "            TargetImage = {'S3Object':{'Bucket':\"350project-image\",'Name':photo}})\n",
    "        result = {}\n",
    "        i = 0\n",
    "        for faceMatch in comparison['FaceMatches']:\n",
    "            position = faceMatch['Face']['BoundingBox']\n",
    "            similarity = faceMatch['Similarity']\n",
    "            result[i] = {}\n",
    "            result[i]['similarity'] = similarity\n",
    "            result[i]['position'] = position['Left']\n",
    "            i+=1\n",
    "        \n",
    "    except Exception:\n",
    "        similarity = np.nan\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'similarity': 99.9999008178711, 'position': 0.2618192732334137}}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_similarity('c2.jpg','c1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly we want to identify if different facial expressions or accessories have a significant impact on the identification of individuals. We thus use five variables in this case, with one being the original picture – “Name” - and one being the control group – “null”. We hope to use the similarity between “name” and “null” as a benchmark to find out whether the differences (if any) found in the mean of the other groups are significant. \n",
    "Here the three groups we use to compare with are: 1) glass-wearing; 2) mask-covering; 3) making funny faces. Their similarity to the original picture is returned as the input in the following table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Claire','Crystal','Gloria','BJT','dl','gql','hj','hzt',\n",
    "         'lhr','lx','mino','whd','wjk','wyb','wyf','yy','yyqx',\n",
    "         'zry','angelina','arriana','cate','emma','emmas','jenniferb',\n",
    "         'jenniferl','jessica','julia','melissa','meryl',\n",
    "        'ruby','scarlett','wendy']\n",
    "image_dict = {'Claire':['a1.jpg','a2.jpg','a3.jpg','a4.jpg','a5.jpg'],\n",
    " 'Crystal':['b1.jpg','b2.jpg','b3.jpg','b4.jpg','b5.jpg'],\n",
    " 'Gloria':['c1.jpg', 'c2.jpg', 'c3.jpg', 'c4.jpg','c5.jpg'],\n",
    " 'BJT':['bjt1.JPG','bjt2.JPG','bjt3.JPG','bjt4.JPG','bjt5.jpg'],\n",
    " 'dl':['dl1.JPG','dl2.JPG','dl3.JPG','dl4.JPG','dl5.jpg'],\n",
    " 'gql':['gql1.JPG','gql2.JPG','gql3.JPG','gql4.JPG','gql5.jpg'],\n",
    " 'hj':['hj1.JPG','hj2.JPG','hj3.JPG','hj4.JPG','hk4.JPG'],\n",
    " 'hzt':['hzt1.JPG','hzt2.JPG','hzt3.JPG','hzt4.JPG','hzt5.jpg'],\n",
    " 'lhr':['lhr1.JPG','lhr2.JPG','lhr3.JPG','lhr4.JPG','lhr5.JPG'],\n",
    " 'lx':['lx1.JPG','lx2.JPG','lx3.JPG','lx4.JPG','lx5.JPG'],\n",
    " 'mino':['mino1.jpg','mino2.JPG','mino3.JPG','mino4.jpg','mino5.jpg'],\n",
    " 'whd':['whd1.JPG','whd2.JPG','whd3.JPG','whd4.JPG','whd5.JPG'],\n",
    " 'wjk':['wjk1.JPG','wjk2.JPG','wjk3.JPG','wjk4.JPG','wjk5.JPG'],\n",
    " 'wyb':['wyb1.JPG','wyb2.JPG','wyb3.JPG','wyb4.JPG','wyb5.JPG'],\n",
    " 'wyf':['wyf1.JPG','wyf2.JPG','wyf3.jpg','wyf4.JPG','wyf5.JPG'],\n",
    " 'yy':['yy1.JPG','yy2.JPG','yy3.jpg','yy4.JPG','yy5.JPG'],\n",
    " 'yyqx':['yyqx1.JPG','yyqx2.JPG','yyqx3.JPG','yyqx4.JPG','yyqx5.JPG'],\n",
    " 'zry':['zry1.JPG','zry2.JPG','zry3.JPG','zry4.JPG','zry5.JPG'],\n",
    " 'angelina':['angelina1.jpg','angelina2.jpg','angelina3.jpg','angelina4.jpg','angelina5.jpg'],\n",
    " 'arriana':['arriana1.jpg','arriana2.jpg','arriana3.jpg','arriana4.jpg','arriana5.jpg'],\n",
    " 'cate':['cate1.jpg','cate2.jpg','cate3.jpg','cate4.jpg','cate5.jpg'],\n",
    " 'emma':['emma1.jpg','emma2.jpg','emma3.jpg','emma4.jpg','emma5.jpg'],\n",
    " 'emmas':['emmas1.jpg','emmas2.jpg','emmas3.jpg','emmas4.jpg','emmas5.jpg'],\n",
    " 'jenniferb':['jenniferb1.jpg','jenniferb2.jpg','jenniferb3.jpg','jenniferb4.png','jenniferb5.jpg'],\n",
    " 'jenniferl':['jenniferl1.jpg','jenniferl2.jpg','jenniferl3.jpg','jenniferl4.jpg','jenniferl5.jpg'],\n",
    " 'jessica':['jessica1.jpg','jessica2.jpg','jessica3.jpg','jessica4.jpg','jessica5.jpg'],\n",
    " 'julia':['julia1.jpg','julia2.jpg','julia3.jpg','julia4.jpg','julia5.jpg'],\n",
    " 'melissa':['melissa1.jpg','melissa2.jpg','melissa3.jpg','melissa4.jpg','melissa5.jpg'],\n",
    " 'meryl':['meryl1.jpg','meryl2.jpg','meryl3.jpg','meryl4.jpg','meryl5.jpg'],\n",
    " 'ruby':['ruby1.jpg','ruby2.jpg','ruby3.jpg','ruby4.jpg','ruby5.jpg'],\n",
    " 'scarlett':['scarlett1.jpg','scarlett2.jpg','scarlett3.jpg','scarlett4.jpg','scarlett5.jpg'],\n",
    " 'wendy':['wendy1.jpg','wendy2.jpg','wendy3.jpg','wendy4.jpg','wendy5.jpg'],\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Name': names})\n",
    "glasses = []\n",
    "mask = []\n",
    "funnyFace = []\n",
    "null = []\n",
    "for name in names: \n",
    "    try:\n",
    "        source_photo = image_dict[name][0]\n",
    "    except:\n",
    "        print(name, \"cannot be read\")\n",
    "    try:\n",
    "        result_glasses = extract_similarity(image_dict[name][1], source_photo)\n",
    "        similarity_glasses = result_glasses[0]['similarity']\n",
    "        glasses.append(similarity_glasses)\n",
    "    except:\n",
    "        glasses.append(np.nan)\n",
    "    try:\n",
    "        result_mask = extract_similarity(image_dict[name][2], source_photo)\n",
    "        similarity_mask = result_mask[0]['similarity']\n",
    "        mask.append(similarity_mask)\n",
    "    except:\n",
    "        mask.append(np.nan)\n",
    "    try:\n",
    "        result_funnyFace = extract_similarity(image_dict[name][3], source_photo)\n",
    "        similarity_funnyFace = result_funnyFace[0]['similarity']\n",
    "        funnyFace.append(similarity_funnyFace)\n",
    "    except:\n",
    "        funnyFace.append(np.nan)\n",
    "    try:\n",
    "        result_null = extract_similarity(image_dict[name][4], source_photo)\n",
    "        similarity_null = result_null[0]['similarity']\n",
    "        null.append(similarity_null)\n",
    "    except:\n",
    "        null.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>glasses</th>\n",
       "      <th>mask</th>\n",
       "      <th>funnyFace</th>\n",
       "      <th>null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claire</td>\n",
       "      <td>99.999962</td>\n",
       "      <td>99.764030</td>\n",
       "      <td>99.998238</td>\n",
       "      <td>99.999550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crystal</td>\n",
       "      <td>99.999977</td>\n",
       "      <td>99.325432</td>\n",
       "      <td>99.999756</td>\n",
       "      <td>99.999496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gloria</td>\n",
       "      <td>99.999901</td>\n",
       "      <td>99.588600</td>\n",
       "      <td>99.879562</td>\n",
       "      <td>99.909981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BJT</td>\n",
       "      <td>99.978279</td>\n",
       "      <td>95.866455</td>\n",
       "      <td>99.648323</td>\n",
       "      <td>99.991486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dl</td>\n",
       "      <td>99.986786</td>\n",
       "      <td>92.788857</td>\n",
       "      <td>99.978821</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gql</td>\n",
       "      <td>99.240044</td>\n",
       "      <td>99.709496</td>\n",
       "      <td>99.630646</td>\n",
       "      <td>99.990356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hj</td>\n",
       "      <td>99.994537</td>\n",
       "      <td>99.856712</td>\n",
       "      <td>99.819168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hzt</td>\n",
       "      <td>99.986603</td>\n",
       "      <td>99.222954</td>\n",
       "      <td>99.964043</td>\n",
       "      <td>99.997429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lhr</td>\n",
       "      <td>99.970398</td>\n",
       "      <td>99.539986</td>\n",
       "      <td>99.897995</td>\n",
       "      <td>99.832001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lx</td>\n",
       "      <td>99.873932</td>\n",
       "      <td>97.319206</td>\n",
       "      <td>99.973778</td>\n",
       "      <td>99.998901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mino</td>\n",
       "      <td>99.990402</td>\n",
       "      <td>97.597694</td>\n",
       "      <td>99.988792</td>\n",
       "      <td>99.972710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>whd</td>\n",
       "      <td>98.465576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.287766</td>\n",
       "      <td>99.989052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wjk</td>\n",
       "      <td>99.928070</td>\n",
       "      <td>81.538406</td>\n",
       "      <td>99.962349</td>\n",
       "      <td>99.994263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wyb</td>\n",
       "      <td>99.939987</td>\n",
       "      <td>93.051865</td>\n",
       "      <td>99.061035</td>\n",
       "      <td>99.980629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wyf</td>\n",
       "      <td>99.939362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.987617</td>\n",
       "      <td>99.999634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>yy</td>\n",
       "      <td>99.994926</td>\n",
       "      <td>81.156937</td>\n",
       "      <td>99.935822</td>\n",
       "      <td>99.996239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>yyqx</td>\n",
       "      <td>99.915268</td>\n",
       "      <td>99.654938</td>\n",
       "      <td>93.648506</td>\n",
       "      <td>99.614838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>zry</td>\n",
       "      <td>99.991196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.953339</td>\n",
       "      <td>99.998024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>angelina</td>\n",
       "      <td>99.928123</td>\n",
       "      <td>97.550323</td>\n",
       "      <td>99.700722</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>arriana</td>\n",
       "      <td>99.705940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.958054</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cate</td>\n",
       "      <td>99.970634</td>\n",
       "      <td>91.091553</td>\n",
       "      <td>99.561760</td>\n",
       "      <td>99.999603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>emma</td>\n",
       "      <td>99.945229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.415489</td>\n",
       "      <td>99.995323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>emmas</td>\n",
       "      <td>99.230209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.999619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>jenniferb</td>\n",
       "      <td>99.509399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.998116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>jenniferl</td>\n",
       "      <td>99.948883</td>\n",
       "      <td>99.698280</td>\n",
       "      <td>99.977020</td>\n",
       "      <td>99.999969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>jessica</td>\n",
       "      <td>99.992691</td>\n",
       "      <td>98.609482</td>\n",
       "      <td>99.866936</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>julia</td>\n",
       "      <td>99.999825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.845093</td>\n",
       "      <td>99.999664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>melissa</td>\n",
       "      <td>99.997955</td>\n",
       "      <td>99.188095</td>\n",
       "      <td>99.697838</td>\n",
       "      <td>99.543221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>meryl</td>\n",
       "      <td>99.983353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.917763</td>\n",
       "      <td>99.999489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ruby</td>\n",
       "      <td>99.972801</td>\n",
       "      <td>99.870743</td>\n",
       "      <td>99.992088</td>\n",
       "      <td>99.998230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>scarlett</td>\n",
       "      <td>99.990807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.760933</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>wendy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.025780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name    glasses       mask  funnyFace        null\n",
       "0      Claire  99.999962  99.764030  99.998238   99.999550\n",
       "1     Crystal  99.999977  99.325432  99.999756   99.999496\n",
       "2      Gloria  99.999901  99.588600  99.879562   99.909981\n",
       "3         BJT  99.978279  95.866455  99.648323   99.991486\n",
       "4          dl  99.986786  92.788857  99.978821         NaN\n",
       "5         gql  99.240044  99.709496  99.630646   99.990356\n",
       "6          hj  99.994537  99.856712  99.819168         NaN\n",
       "7         hzt  99.986603  99.222954  99.964043   99.997429\n",
       "8         lhr  99.970398  99.539986  99.897995   99.832001\n",
       "9          lx  99.873932  97.319206  99.973778   99.998901\n",
       "10       mino  99.990402  97.597694  99.988792   99.972710\n",
       "11        whd  98.465576        NaN  99.287766   99.989052\n",
       "12        wjk  99.928070  81.538406  99.962349   99.994263\n",
       "13        wyb  99.939987  93.051865  99.061035   99.980629\n",
       "14        wyf  99.939362        NaN  99.987617   99.999634\n",
       "15         yy  99.994926  81.156937  99.935822   99.996239\n",
       "16       yyqx  99.915268  99.654938  93.648506   99.614838\n",
       "17        zry  99.991196        NaN  99.953339   99.998024\n",
       "18   angelina  99.928123  97.550323  99.700722  100.000000\n",
       "19    arriana  99.705940        NaN  99.958054  100.000000\n",
       "20       cate  99.970634  91.091553  99.561760   99.999603\n",
       "21       emma  99.945229        NaN  97.415489   99.995323\n",
       "22      emmas  99.230209        NaN        NaN   99.999619\n",
       "23  jenniferb  99.509399        NaN        NaN   99.998116\n",
       "24  jenniferl  99.948883  99.698280  99.977020   99.999969\n",
       "25    jessica  99.992691  98.609482  99.866936         NaN\n",
       "26      julia  99.999825        NaN  99.845093   99.999664\n",
       "27    melissa  99.997955  99.188095  99.697838   99.543221\n",
       "28      meryl  99.983353        NaN  99.917763   99.999489\n",
       "29       ruby  99.972801  99.870743  99.992088   99.998230\n",
       "30   scarlett  99.990807        NaN  82.760933  100.000000\n",
       "31      wendy        NaN  87.025780        NaN         NaN"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['glasses'] = glasses\n",
    "df['mask'] = mask\n",
    "df['funnyFace'] = funnyFace\n",
    "df['null'] = null\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dataframe, we can see that the column of 'mask' contains many nan values, which means AWS Rekognition fails to identify the person from the photo of the person wearing mask. Then, we use a boxplot to better visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot = df.boxplot(column = ['null','glasses', 'mask', 'funnyFace'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The boxplot confirms our initial thought that each group has a different mean, especially the mask group. So we conduct a hypothesis testing:\n",
    "\n",
    "    Null Hypothesis: There is no significant difference between the means of the variables. \n",
    "    Alternative Hypothesis: There is a significant difference between the means of the variables.\n",
    "    Testing Method: One-way ANOVA Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "F,p = f_oneway(df['null'][~np.isnan(df['null'])],df['glasses'][~np.isnan(df['glasses'])], df['mask'][~np.isnan(df['mask'])], df['funnyFace'][~np.isnan(df['funnyFace'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.017194794507072"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2639456311411546e-05"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: The One-way ANOVA Testing shows an output F value of 9.017 and p-value=0.0000226. Using a 5% significance level, it shows that there is a 0.00226% risk of concluding that a difference exists when there is no actual difference. Thus, we reject the null hypothesis and conclude that not all population means are equal. \n",
    "\n",
    "But the ANOVA test only shows that it is likely that the four groups have a difference in mean, but it has not signified which groups is most likely to differ or which group differs by most. Therefore, we optimize our testing method by using T tests. \n",
    "\n",
    "    Null Hypothesis: There is no significant difference between the mean in the “glasses” group and the “null group. \n",
    "    Alternative Hypothesis: There is a significant difference between the mean in the “glasses” group and the “null” group.\n",
    "    Testing Method: T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.702134484078732, pvalue=0.09696730057681158)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(df['null'][~np.isnan(df['null'])],df['glasses'][~np.isnan(df['glasses'])], equal_var = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=3.3054977110315362, pvalue=0.003364403260063759)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(df['null'][~np.isnan(df['null'])],df['mask'][~np.isnan(df['mask'])], equal_var = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.632198656154107, pvalue=0.11380903555402896)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(df['null'][~np.isnan(df['null'])],df['funnyFace'][~np.isnan(df['funnyFace'])], equal_var = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the image of people wearing glasses, masks, and making funny faces with their daily pictures respectively, we could find that the p values are 0.097, 0.0034 and 0.114. Comparing with p=0.05, we can only reject the second group of which p=0.0034. We reject the null hypothesis that there is no difference between the mean of the group when people wear masks and when they are not. \n",
    "\n",
    "Combing our clusion with our observation from the dataframe, we finds that with the person wearing a mask in the photo, AWS Rekognition has higher probability to fail to regonize the person (by 'nan' fromt the dataframe), and for the part that AWS Rekognition match the faces with masks successfully, the mean similarity score is different from that of regular photos ('null') by T-test. This indicates that AWS Rekognition is less confident to identify people when they wear masks. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Because the mean similarity is significantly different between regular photos and photos with the person wearing mask, we conclude that Amazon Rekognition is less confident to identify faces when the individuals are wearing masks. \n",
    "\n",
    "We conclude that Amazon Rekognition still recognizes the individuals when they are wearing glasses and making funny faces. We also conclude that Amazon Rekognition is able to tell the twin sisters apart. \n",
    "\n",
    "Amazon Rekognition is relatively accurate in facial recognitions. The developers can look for ways that improve facial recognition when the individuals are wearing masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
